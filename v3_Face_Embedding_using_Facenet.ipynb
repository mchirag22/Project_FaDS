{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from deepface import DeepFace\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "from deepface import DeepFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is not available. PyTorch is using the CPU.\n"
     ]
    }
   ],
   "source": [
    "# Check if a GPU is available and set the device accordingly\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Check if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available. PyTorch is using the GPU.\")\n",
    "    print(f\"Device name: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"CUDA is not available. PyTorch is using the CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the YOLOv8 model and move it to the GPU if available\n",
    "model = YOLO('yolov8n-face.pt').to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directory to save detected faces\n",
    "os.makedirs('just_faces', exist_ok=True)\n",
    "\n",
    "# Load and prepare the image\n",
    "image_path = 'test_images_big/DSC_1064 1.JPG'\n",
    "image = cv2.imread(image_path)\n",
    "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert to RGB for detection\n",
    "\n",
    "# Perform face detection\n",
    "results = model(image_rgb)\n",
    "\n",
    "# Process results and save detected faces\n",
    "for i, result in enumerate(results):\n",
    "    boxes = result.boxes\n",
    "\n",
    "    for j, box in enumerate(boxes):\n",
    "        xyxy = box.xyxy[0].cpu().numpy()  # Get coordinates as a numpy array\n",
    "        conf = box.conf[0].cpu().numpy() if box.conf is not None else 0  # Extract confidence\n",
    "\n",
    "        if conf > 0.1:  # Confidence threshold\n",
    "            x1, y1, x2, y2 = map(int, xyxy)\n",
    "\n",
    "            # Extract face\n",
    "            face_crop = image[y1:y2, x1:x2]\n",
    "\n",
    "            # Save face crop as an image\n",
    "            face_path = os.path.join('just_faces', f'face_{i}_{j}.jpg')\n",
    "            cv2.imwrite(face_path, face_crop)\n",
    "\n",
    "print(\"Detected faces have been saved in the 'just_faces' folder.\")\n",
    "\n",
    "# Path to the folder containing detected faces\n",
    "faces_folder_path = 'just_faces'\n",
    "\n",
    "# Function to get embeddings for each face image\n",
    "def get_face_embeddings(face_image_path, model_name='Facenet'):\n",
    "    # Get the embedding using DeepFace\n",
    "    embeddings = DeepFace.represent(img_path=face_image_path, model_name=model_name, enforce_detection=False)\n",
    "    return embeddings\n",
    "\n",
    "# Get embeddings for all face images in the folder\n",
    "face_embeddings = []\n",
    "\n",
    "for face_image_name in os.listdir(faces_folder_path):\n",
    "    face_image_path = os.path.join(faces_folder_path, face_image_name)\n",
    "    \n",
    "    if os.path.isfile(face_image_path):  # Check if it's a file\n",
    "        try:\n",
    "            embeddings = get_face_embeddings(face_image_path)\n",
    "            face_embeddings.append(embeddings[0]['embedding'])\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {face_image_path}: {e}\")\n",
    "\n",
    "# Print the embeddings\n",
    "for i, embedding in enumerate(face_embeddings):\n",
    "    print(f\"Embedding for face {i+1}: {embedding}\")\n",
    "\n",
    "# Optionally, save the embeddings to a file\n",
    "np.save('face_embeddings.npy', face_embeddings)\n",
    "print(\"Face embeddings have been saved to 'face_embeddings.npy'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 6 faces, 49.1ms\n",
      "Speed: 2.0ms preprocess, 49.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Face embeddings have been saved to 'embeddings/DSC_1064 1.npy'.\n"
     ]
    }
   ],
   "source": [
    "# Create directories for saving embeddings\n",
    "os.makedirs('embeddings', exist_ok=True)\n",
    "\n",
    "# Load and prepare the image\n",
    "image_path = 'test_images_big/DSC_1064 1.JPG'\n",
    "image = cv2.imread(image_path)\n",
    "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert to RGB for detection\n",
    "\n",
    "# Perform face detection\n",
    "results = model(image_rgb)\n",
    "\n",
    "# Process results and get embeddings\n",
    "face_embeddings = []\n",
    "\n",
    "for result in results:\n",
    "    boxes = result.boxes\n",
    "\n",
    "    for box in boxes:\n",
    "        xyxy = box.xyxy[0].cpu().numpy()  # Get coordinates as a numpy array\n",
    "        conf = box.conf[0].cpu().numpy() if box.conf is not None else 0  # Extract confidence\n",
    "\n",
    "        if conf > 0.1:  # Confidence threshold\n",
    "            x1, y1, x2, y2 = map(int, xyxy)\n",
    "\n",
    "            # Extract face\n",
    "            face_crop = image[y1:y2, x1:x2]\n",
    "\n",
    "            # Convert face crop to RGB and save for embedding extraction\n",
    "            face_crop_rgb = cv2.cvtColor(face_crop, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            # Get the embedding using DeepFace\n",
    "            try:\n",
    "                embeddings = DeepFace.represent(img_path=face_crop_rgb, model_name='Facenet', enforce_detection=False)\n",
    "                face_embeddings.append(embeddings[0]['embedding'])\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing detected face: {e}\")\n",
    "\n",
    "# Save embeddings to a file with the original image name\n",
    "base_name = os.path.splitext(os.path.basename(image_path))[0]\n",
    "np.save(os.path.join('embeddings', f'{base_name}.npy'), face_embeddings)\n",
    "print(f\"Face embeddings have been saved to 'embeddings/{base_name}.npy'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images: 100%|██████████| 1197/1197 [19:27<00:00,  1.03image/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Create directories for saving embeddings\n",
    "os.makedirs('embeddings', exist_ok=True)\n",
    "\n",
    "\n",
    "# Path to the directory containing images\n",
    "image_dir = 'test_images_big'  # Change this to your directory\n",
    "\n",
    "# Get all image files in the specified directory\n",
    "image_files = [f for f in os.listdir(image_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "\n",
    "# Loop through all image files with a single progress bar\n",
    "with tqdm(total=len(image_files), desc=\"Processing Images\", unit=\"image\") as pbar:\n",
    "    for image_name in image_files:\n",
    "        image_path = os.path.join(image_dir, image_name)\n",
    "\n",
    "        # Load and prepare the image\n",
    "        image = cv2.imread(image_path)\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert to RGB for detection\n",
    "\n",
    "        # Perform face detection (set verbose to False if applicable)\n",
    "        results = model(image_rgb, verbose=False)\n",
    "\n",
    "        # Process results and get embeddings\n",
    "        face_embeddings = []\n",
    "\n",
    "        for result in results:\n",
    "            boxes = result.boxes\n",
    "\n",
    "            for box in boxes:\n",
    "                xyxy = box.xyxy[0].cpu().numpy()  # Get coordinates as a numpy array\n",
    "                conf = box.conf[0].cpu().numpy() if box.conf is not None else 0  # Extract confidence\n",
    "\n",
    "                if conf > 0.1:  # Confidence threshold\n",
    "                    x1, y1, x2, y2 = map(int, xyxy)\n",
    "\n",
    "                    # Extract face\n",
    "                    face_crop = image[y1:y2, x1:x2]\n",
    "\n",
    "                    # Convert face crop to RGB for embedding extraction\n",
    "                    face_crop_rgb = cv2.cvtColor(face_crop, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "                    # Get the embedding using DeepFace\n",
    "                    try:\n",
    "                        embeddings = DeepFace.represent(img_path=face_crop_rgb, model_name='Facenet', enforce_detection=False)\n",
    "                        face_embeddings.append(embeddings[0]['embedding'])\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error processing detected face in {image_name}: {e}\")\n",
    "\n",
    "        # Save embeddings to a file with the original image name\n",
    "        if face_embeddings:\n",
    "            base_name = os.path.splitext(os.path.basename(image_path))[0]\n",
    "            np.save(os.path.join('embeddings', f'{base_name}.npy'), face_embeddings)\n",
    "\n",
    "        # Update progress bar\n",
    "        pbar.update(1)\n",
    "\n",
    "print(\"Processing complete.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolov8env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
