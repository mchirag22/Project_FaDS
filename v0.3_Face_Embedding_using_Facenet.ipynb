{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From e:\\Apps\\Anaconda\\envs\\yolov8env\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from deepface import DeepFace\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "from deepface import DeepFace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if GPU Computing is Available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is not available. PyTorch is using the CPU.\n"
     ]
    }
   ],
   "source": [
    "# Check if a GPU is available and set the device accordingly\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Check if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available. PyTorch is using the GPU.\")\n",
    "    print(f\"Device name: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"CUDA is not available. PyTorch is using the CPU.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Face Detection Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the YOLOv8 model and move it to the GPU if available\n",
    "model = YOLO('yolov8n-face.pt').to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Face Embeddings for the Entire Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images: 100%|██████████| 76/76 [00:49<00:00,  1.54image/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Path to the directory containing images\n",
    "image_dir = r'G:\\Computer_Vision\\Data\\Goa'  # Change this to your directory\n",
    "input_folder_name = os.path.basename(image_dir)\n",
    "output_folder_name = f\"{input_folder_name}_embeddings\"\n",
    "meta_data_folder = os.path.join(os.path.dirname(image_dir), 'meta_data', output_folder_name)\n",
    "\n",
    "# Create directories for saving embeddings\n",
    "os.makedirs(meta_data_folder, exist_ok=True)\n",
    "\n",
    "# Get all image files in the specified directory\n",
    "image_files = [f for f in os.listdir(image_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "\n",
    "# Loop through all image files with a single progress bar\n",
    "with tqdm(total=len(image_files), desc=\"Processing Images\", unit=\"image\") as pbar:\n",
    "    for image_name in image_files:\n",
    "        image_path = os.path.join(image_dir, image_name)\n",
    "\n",
    "        # Load and prepare the image\n",
    "        image = cv2.imread(image_path)\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert to RGB for detection\n",
    "\n",
    "        # Perform face detection (set verbose to False if applicable)\n",
    "        results = model(image_rgb, verbose=False)\n",
    "\n",
    "        # Process results and get embeddings\n",
    "        face_embeddings = []\n",
    "\n",
    "        for result in results:\n",
    "            boxes = result.boxes\n",
    "\n",
    "            for box in boxes:\n",
    "                xyxy = box.xyxy[0].cpu().numpy()  # Get coordinates as a numpy array\n",
    "                conf = box.conf[0].cpu().numpy() if box.conf is not None else 0  # Extract confidence\n",
    "\n",
    "                if conf > 0.1:  # Confidence threshold\n",
    "                    x1, y1, x2, y2 = map(int, xyxy)\n",
    "\n",
    "                    # Extract face\n",
    "                    face_crop = image[y1:y2, x1:x2]\n",
    "\n",
    "                    # Convert face crop to RGB for embedding extraction\n",
    "                    face_crop_rgb = cv2.cvtColor(face_crop, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "                    # Get the embedding using DeepFace\n",
    "                    try:\n",
    "                        embeddings = DeepFace.represent(img_path=face_crop_rgb, model_name='Facenet', enforce_detection=False)\n",
    "                        face_embeddings.append(embeddings[0]['embedding'])\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error processing detected face in {image_name}: {e}\")\n",
    "\n",
    "        # Save embeddings to a file with the original image name\n",
    "        if face_embeddings:\n",
    "            base_name = os.path.splitext(os.path.basename(image_path))[0]\n",
    "            np.save(os.path.join(meta_data_folder, f'{base_name}.npy'), face_embeddings)\n",
    "\n",
    "        # Update progress bar\n",
    "        pbar.update(1)\n",
    "\n",
    "print(\"Processing complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# consistant variant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the directory containing images\n",
    "image_dir = r'G:\\Computer_Vision\\Data\\Goa'  # Change this to your directory\n",
    "input_folder_name = os.path.basename(image_dir)\n",
    "output_folder_name = f\"{input_folder_name}_embeddings\"\n",
    "meta_data_folder = os.path.join(os.path.dirname(image_dir), 'meta_data', output_folder_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images: 100%|██████████| 76/76 [00:45<00:00,  1.66image/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Create directories for saving embeddings\n",
    "os.makedirs(meta_data_folder, exist_ok=True)\n",
    "\n",
    "# Get all image files in the specified directory\n",
    "image_files = [f for f in os.listdir(image_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "\n",
    "# Define a function to preprocess face crops\n",
    "def preprocess_face_crop(face_crop):\n",
    "    return cv2.cvtColor(face_crop, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Define a function to get embeddings\n",
    "def get_face_embeddings(face_crop):\n",
    "    try:\n",
    "        embeddings = DeepFace.represent(img_path=face_crop, model_name='Facenet', enforce_detection=False)\n",
    "        return embeddings[0]['embedding']\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing face crop: {e}\")\n",
    "        return None\n",
    "\n",
    "# Process images with a progress bar\n",
    "with tqdm(total=len(image_files), desc=\"Processing Images\", unit=\"image\") as pbar:\n",
    "    for image_name in image_files:\n",
    "        image_path = os.path.join(image_dir, image_name)\n",
    "        image = cv2.imread(image_path)\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Perform face detection\n",
    "        results = model(image_rgb, verbose=False)\n",
    "        face_embeddings = []\n",
    "\n",
    "        for result in results:\n",
    "            boxes = result.boxes\n",
    "\n",
    "            for box in boxes:\n",
    "                xyxy = box.xyxy[0].cpu().numpy()\n",
    "                conf = box.conf[0].cpu().numpy() if box.conf is not None else 0\n",
    "\n",
    "                if conf > 0.1:\n",
    "                    x1, y1, x2, y2 = map(int, xyxy)\n",
    "                    face_crop = image[y1:y2, x1:x2]\n",
    "                    face_crop_rgb = preprocess_face_crop(face_crop)\n",
    "                    embedding = get_face_embeddings(face_crop_rgb)\n",
    "                    if embedding is not None:\n",
    "                        face_embeddings.append(embedding)\n",
    "\n",
    "        if face_embeddings:\n",
    "            base_name = os.path.splitext(os.path.basename(image_path))[0]\n",
    "            np.save(os.path.join(meta_data_folder, f'{base_name}.npy'), face_embeddings)\n",
    "\n",
    "        pbar.update(1)\n",
    "\n",
    "print(\"Processing complete.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolov8env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
